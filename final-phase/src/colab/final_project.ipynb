{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npS1pEUSesRz"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install torchmetrics\n",
        "!pip install pytorch_lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1"
      ],
      "metadata": {
        "id": "dtY0dbC5e8-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from torch import nn\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import csv\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer, BertModel, BertForMaskedLM, AdamW\n",
        "from torchmetrics import Accuracy\n",
        "import os\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import tqdm\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "GECAgb1ye_dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = '/content/drive/MyDrive/data'\n",
        "\n",
        "train_data_path = f'{data_path}/train'\n",
        "true_train_path = f'{train_data_path}/true.csv'\n",
        "false_train_path = f'{train_data_path}/false.csv'"
      ],
      "metadata": {
        "id": "uAqYu84ifEww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "true_label = 1\n",
        "false_label = 0\n",
        "\n",
        "true_saved_model_path = '/content/drive/MyDrive/models/true_bert_lm.pt'\n",
        "false_saved_model_path = '/content/drive/MyDrive/models/false_bert_lm.pt'"
      ],
      "metadata": {
        "id": "ozrqLHpWfGQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LMSpellCheckingDataset(Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, data_paths, labels, batch_size=32):\n",
        "        self.dataset = []\n",
        "        for i in range(len(data_paths)):\n",
        "          data_path = data_paths[i]\n",
        "          with open(data_path, 'r', encoding='utf-8') as file:\n",
        "              data = csv.reader(file)\n",
        "              for item in data:\n",
        "                self.dataset.append((item[0], labels[i]))\n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if (self.tokenizer == None):\n",
        "          raise Exception('Tokenizer cannot be null')\n",
        "\n",
        "        tweet, label = self.dataset[idx]\n",
        "        tokenized_tweet = self.tokenizer(tweet)\n",
        "        input_ids = tokenized_tweet['input_ids']\n",
        "        attention_mask = tokenized_tweet['attention_mask']\n",
        "\n",
        "        return torch.tensor(input_ids)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "class BertLM(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, class_name):\n",
        "        super().__init__()\n",
        "        self.bert = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "        self.epoch_number = 0\n",
        "        self.class_name = class_name\n",
        "\n",
        "    def forward(self, input_ids, labels):\n",
        "        return self.bert(input_ids=input_ids,labels=labels)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        outputs = self(input_ids=input_ids, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        super().training_epoch_end(outputs)\n",
        "        mean_loss = 0\n",
        "        n_batch  = len(outputs)\n",
        "        for i in range(n_batch):\n",
        "            mean_loss += outputs[i]['loss'].cpu().numpy() / n_batch\n",
        "        print(f\"End of epoch {self.epoch_number} with mean loss '{mean_loss}' on label {self.class_name}.\", \"fine_tuning\")\n",
        "        self.epoch_number += 1\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.parameters(), lr=1e-5)\n",
        "\n",
        "class BertLMPred(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bert = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def forward(self, input_ids, labels=None):\n",
        "        return self.bert(input_ids=input_ids,labels=labels)"
      ],
      "metadata": {
        "id": "Qh17pWES1iEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MASK = '[MASK]'\n",
        "SEP = '[SEP]'\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize_batch(batch, tokenizer):\n",
        "    return [tokenizer.convert_tokens_to_ids(sent) for sent in batch]\n",
        "\n",
        "def get_init_text(seed_sentence, max_len, tokenizer, batch_size=1):\n",
        "    batch = [seed_sentence + [MASK] * max_len + [SEP] for _ in range(batch_size)]\n",
        "    return tokenize_batch(batch, tokenizer)\n",
        "\n",
        "def untokenize_batch(batch, tokenizer):\n",
        "    return [tokenizer.convert_ids_to_tokens(sent) for sent in batch]\n",
        "\n",
        "def generate_step(out, gen_idx, temperature=None, top_k=0, \n",
        "                  sample=False, return_list=True):\n",
        "    \"\"\" Generate a word from from out[gen_idx]\n",
        "    \n",
        "    args:\n",
        "        - out (torch.Tensor): tensor of logits of size batch_size x seq_len x vocab_size\n",
        "        - gen_idx (int): location for which to generate for\n",
        "        - top_k (int): if >0, only sample from the top k most probable words\n",
        "        - sample (Bool): if True, sample from full distribution. Overridden by top_k \n",
        "    \"\"\"\n",
        "    logits = out.logits[:, gen_idx]\n",
        "    if temperature is not None:\n",
        "        logits = logits / temperature\n",
        "    if top_k > 0:\n",
        "        kth_vals, kth_idx = logits.topk(top_k, dim=-1)\n",
        "        dist = torch.distributions.categorical.Categorical(logits=kth_vals)\n",
        "        idx = kth_idx.gather(dim=1, index=dist.sample().unsqueeze(-1)).squeeze(-1)\n",
        "    elif sample:\n",
        "        dist = torch.distributions.categorical.Categorical(logits=logits)\n",
        "        idx = dist.sample().squeeze(-1)\n",
        "    else:\n",
        "        idx = torch.argmax(logits, dim=-1)\n",
        "    return idx.tolist() if return_list else idx\n",
        "\n",
        "\n",
        "def parallel_sequential_generation(seed_text, tokenizer, model, batch_size=1, \n",
        "                                   max_len=15, top_k=0, temperature=None, \n",
        "                                   max_iter=300, burnin=200, cuda=False, \n",
        "                                   print_every=10, verbose=True):\n",
        "    \"\"\" Generate for one random position at a timestep\n",
        "    \n",
        "    args:\n",
        "        - burnin: during burn-in period, sample from full distribution; afterwards take argmax\n",
        "    \"\"\"\n",
        "    seed_len = len(seed_text)\n",
        "    batch = get_init_text(seed_text, max_len, tokenizer, batch_size=batch_size)\n",
        "    mask_id = tokenizer.convert_tokens_to_ids([MASK])[0]\n",
        "    for ii in range(max_iter):\n",
        "        kk = np.random.randint(0, max_len)\n",
        "        for jj in range(batch_size):\n",
        "            batch[jj][seed_len+kk] = mask_id\n",
        "        inp = torch.tensor(batch).cuda() if cuda else torch.tensor(batch)\n",
        "        out = model(inp)\n",
        "        topk = top_k if (ii >= burnin) else 0\n",
        "        idxs = generate_step(out, gen_idx=seed_len+kk, top_k=topk, temperature=temperature, sample=(ii < burnin))\n",
        "        #if idxs is a single number\n",
        "        if isinstance(idxs, int):\n",
        "            idxs = [idxs]\n",
        "        for jj in range(batch_size):\n",
        "            batch[jj][seed_len+kk] = idxs[jj]\n",
        "            \n",
        "    return untokenize_batch(batch, tokenizer)\n",
        "\n",
        "\n",
        "def generate(tokenizer, n_samples, class_name, model, seed_text=\"[CLS]\", \n",
        "             batch_size=1, max_len=25, sample=True, top_k=100, temperature=1.0, \n",
        "             burnin=200, max_iter=500, cuda=False, print_every=1):\n",
        "    # main generation function to call\n",
        "    sentences = []\n",
        "    n_batches = math.ceil(n_samples / batch_size)\n",
        "    start_time = time.time()\n",
        "    for batch_n in range(n_batches):\n",
        "        batch = parallel_sequential_generation(seed_text, tokenizer, model, \n",
        "                                               max_len=max_len, top_k=top_k,\n",
        "                                               temperature=temperature, \n",
        "                                               burnin=burnin, max_iter=max_iter, \n",
        "                                               cuda=cuda, verbose=False)\n",
        "        \n",
        "        if (batch_n + 1) % print_every == 0:\n",
        "            print(\"Finished batch %d in %.3fs\" % (batch_n + 1, time.time() - start_time))\n",
        "            print(\"Finished batch %d in %.3fs\" % (batch_n + 1, time.time() - start_time), \"fine_tuning\")\n",
        "            start_time = time.time()\n",
        "        \n",
        "        sentences += batch\n",
        "    return sentences\n",
        "\n",
        "def standardize_sentence(sent):\n",
        "    sentence = []\n",
        "    current_word = sent[0]\n",
        "    for i in range(1, len(sent)):\n",
        "        token = sent[i]\n",
        "        if(token[0:2] == '##'):\n",
        "            current_word += token[2:]\n",
        "        else:\n",
        "            sentence.append(current_word)\n",
        "            current_word = token\n",
        "    sentence.append(current_word)\n",
        "    return sentence\n",
        "\n",
        "def fine_tune_LM(class_name, tokenizer, epochs, batch_size, \n",
        "                 train_paths, labels, save_url=None, mlm_prob=0.25, \n",
        "                 use_gpu=True):\n",
        "  \n",
        "    dataset = LMSpellCheckingDataset(tokenizer, train_paths, labels)\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, \n",
        "                                                    mlm=True, \n",
        "                                                    mlm_probability=mlm_prob)\n",
        "    train_loader = DataLoader(dataset, \n",
        "                              batch_size=batch_size, \n",
        "                              collate_fn=data_collator)\n",
        "    model = BertLM(class_name)\n",
        "    #using CPU\n",
        "    if use_gpu:\n",
        "        trainer = pl.Trainer(max_epochs=epochs, \n",
        "                             checkpoint_callback=False, \n",
        "                             logger=False, \n",
        "                             gpus=1)\n",
        "    else:\n",
        "        trainer = pl.Trainer(max_epochs=epochs, \n",
        "                             checkpoint_callback=False, \n",
        "                             logger=False)\n",
        "        \n",
        "    print(f\"Start fine tuning BERT masked LM on class {class_name}\", \"fine_tuning\")\n",
        "    trainer.fit(model, train_loader)\n",
        "    if save_url is not None:\n",
        "        print(f\"Finished training. Saving model in {save_url}\", \"fine_tuning\")\n",
        "        torch.save(model.state_dict(), save_url)\n",
        "\n",
        "def fine_tune(tokenizer):\n",
        "    labels = ['false', 'true']\n",
        "    bert_model_url = \"/content/drive/MyDrive/models/\"\n",
        "    reports_dir = \"/content/drive/MyDrive/reports/\"\n",
        "    if not os.path.exists(reports_dir):\n",
        "        os.makedirs(reports_dir, exist_ok=True)\n",
        "    labels = [item for item in labels]\n",
        "    \n",
        "    for label in labels:\n",
        "        print('----------\\n')\n",
        "        print(f\"Generating sentences for {label} label ...\", \"fine_tuning\")\n",
        "        model_url = os.path.join(bert_model_url, f\"{label}_bert_lm.pt\")\n",
        "        model = BertLMPred()\n",
        "        model.load_state_dict(torch.load(model_url))\n",
        "        model = model.cuda()\n",
        "        sentences = generate(tokenizer, 10, label, model, max_len=10, seed_text='[CLS]'.split(), cuda=True)\n",
        "        out_url = reports_dir + f\"{label}.txt\"\n",
        "        with open(out_url, 'w') as outf:\n",
        "            for sent in sentences:\n",
        "                sent = standardize_sentence(sent)\n",
        "                outf.write(' '.join(sent).replace('[', '<').replace(']', '>'))\n",
        "                outf.write(\"\\\\\\\\\")\n",
        "                outf.write(\"\\n\")\n",
        "        print(f\"Sentences for {label} saved to {out_url}.\", \"fine_tuning\")\n",
        "        print(sentences)\n",
        "        print('----------\\n')\n",
        "        \n",
        "fine_tune_LM('true', tokenizer, 20, 32, [true_train_path], [true_label], \n",
        "             save_url=true_saved_model_path)\n",
        "\n",
        "fine_tune_LM('false', tokenizer, 20, 32, [false_train_path], [false_label], \n",
        "             save_url=false_saved_model_path)\n",
        "\n",
        "fine_tune(tokenizer)\n"
      ],
      "metadata": {
        "id": "JqciaevS-GSU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503,
          "referenced_widgets": [
            "ed04914815634c35b95b1cebf59be9e6",
            "f2d1270f65fb4f60861ba0a68ca2db5f",
            "59585ce1681d4e009a983d5142086b27",
            "74ed83a31e8a41e6a816a3ecac79338e",
            "9a77dcc51f974545b7ad6417b0303446",
            "541bd3043dcc47b181eff4b629f9d3b6",
            "250d35418a154aabaa58ff9f7855497a",
            "b3bfe49c82254e12870360aafd10c2f0",
            "271bb9dea723447487783845dca07ae2",
            "6087ad59f1c0459c81186cc8543132de",
            "3b9a034289fa4a439d7df253283b1059"
          ]
        },
        "outputId": "5961f1f1-7b7b-4084-dac6-3d204f267a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:152: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
            "  f\"Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will \"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start fine tuning BERT masked LM on class true fine_tuning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "\n",
            "  | Name | Type            | Params\n",
            "-----------------------------------------\n",
            "0 | bert | BertForMaskedLM | 109 M \n",
            "-----------------------------------------\n",
            "109 M     Trainable params\n",
            "0         Non-trainable params\n",
            "109 M     Total params\n",
            "438.057   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed04914815634c35b95b1cebf59be9e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished training. Saving model in /content/drive/MyDrive/models/true_bert_lm.pt fine_tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2"
      ],
      "metadata": {
        "id": "plpmWtHffPYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KYETeqqTQxq",
        "outputId": "4e5950dd-ef9f-4a0d-b867-e77e7bef1999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = '/content/drive/MyDrive/University/NLP/Final-Project/data'\n",
        "# data_path = '/content/drive/MyDrive/data'\n",
        "\n",
        "train_data_path = f'{data_path}/train'\n",
        "true_train_path = f'{train_data_path}/true.csv'\n",
        "false_train_path = f'{train_data_path}/false.csv'\n",
        "\n",
        "test_data_path = f'{data_path}/test'\n",
        "true_test_path = f'{test_data_path}/true.csv'\n",
        "false_test_path = f'{test_data_path}/false.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cb6-ij9SgvY",
        "outputId": "863c52d0-b8bc-4be5-cedb-af0555e6288e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch's nn module has lots of useful feature\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import csv\n",
        "\n",
        "def pad_batched_sequence(batch):\n",
        "    tweets = []\n",
        "    tweets_lengths = []\n",
        "    labels = []\n",
        "    for (tweet, label) in batch:\n",
        "      tweets.append(torch.tensor(tweet).cuda())\n",
        "      tweets_lengths.append(len(tweet))\n",
        "      labels.append(label)\n",
        "\n",
        "    tweets = pad_sequence(tweets, padding_value=0, batch_first=True).cuda()\n",
        "    tweets_lengths = torch.tensor(tweets_lengths).cuda()\n",
        "    labels = torch.tensor(labels).cuda()\n",
        "    return tweets, tweets_lengths, labels\n",
        "\n",
        "word_to_idx = {\n",
        "  '<pad>': 0,\n",
        "  '<start>': 1,\n",
        "  '<stop>': 2\n",
        "}\n",
        "class SpellCheckingDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_paths, labels, batch_size=32):\n",
        "        self.dataset = []\n",
        "        \n",
        "        idx = 3\n",
        "        for i in range(len(data_paths)):\n",
        "          data_path = data_paths[i]\n",
        "          with open(data_path, 'r', encoding='utf-8') as file:\n",
        "              data = csv.reader(file)\n",
        "              for item in data:\n",
        "                tokenized_tweet = ['<start>'] + word_tokenize(item[0]) + ['<stop>']\n",
        "                for word in tokenized_tweet:\n",
        "                  if (word not in word_to_idx):\n",
        "                    word_to_idx[word] = idx\n",
        "                    idx += 1\n",
        "                self.dataset.append((tokenized_tweet, labels[i]))\n",
        "        self.batch_size = batch_size\n",
        "        self.vocab_size = len(word_to_idx)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return [word_to_idx[w] for w in self.dataset[idx][0]], self.dataset[idx][1]\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "class LSTMNet(nn.Module):\n",
        "    \n",
        "    def __init__(self,vocab_size,embedding_dim,hidden_dim,output_dim,n_layers,bidirectional,dropout):\n",
        "        \n",
        "        super(LSTMNet,self).__init__()\n",
        "        \n",
        "        # Embedding layer converts integer sequences to vector sequences\n",
        "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "        \n",
        "        # LSTM layer process the vector sequences \n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers = n_layers,\n",
        "                            bidirectional = bidirectional,\n",
        "                            dropout = dropout,\n",
        "                            batch_first = True\n",
        "                           )\n",
        "        \n",
        "        # Dense layer to predict \n",
        "        self.fc = nn.Linear(hidden_dim * 2,output_dim)\n",
        "        # Prediction activation function\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    \n",
        "    def forward(self,text,text_lengths):\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # Thanks to packing, LSTM don't see padding tokens \n",
        "        # and this makes our model better\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(),batch_first=True, enforce_sorted=False)\n",
        "        \n",
        "        packed_output,(hidden_state,cell_state) = self.lstm(packed_embedded)\n",
        "        \n",
        "        # Concatenating the final forward and backward hidden states\n",
        "        hidden = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)\n",
        "        \n",
        "        dense_outputs=self.fc(hidden)\n",
        "\n",
        "        #Final activation function\n",
        "        outputs=self.sigmoid(dense_outputs)\n",
        "        \n",
        "        return outputs\n",
        "    "
      ],
      "metadata": {
        "trusted": true,
        "id": "OL0CeKtRBKYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "true_label = 1\n",
        "false_label = 0\n",
        "\n",
        "train_dataset = SpellCheckingDataset([true_train_path, false_train_path], \n",
        "                                          [true_label, false_label])\n",
        "\n",
        "test_dataset = SpellCheckingDataset([true_test_path, false_test_path], \n",
        "                                          [true_label, false_label])\n",
        "\n",
        "SIZE_OF_VOCAB = train_dataset.vocab_size\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_HIDDEN_NODES = 64\n",
        "NUM_OUTPUT_NODES = 1\n",
        "NUM_LAYERS = 2\n",
        "BIDIRECTION = True\n",
        "DROPOUT = 0.2"
      ],
      "metadata": {
        "trusted": true,
        "id": "tHdNQyocBKYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMNet(SIZE_OF_VOCAB,\n",
        "                EMBEDDING_DIM,\n",
        "                NUM_HIDDEN_NODES,\n",
        "                NUM_OUTPUT_NODES,\n",
        "                NUM_LAYERS,\n",
        "                BIDIRECTION,\n",
        "                DROPOUT\n",
        "               )\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "duYyBIzqBKYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
        "criterion = nn.BCELoss()\n",
        "criterion = criterion.cuda()"
      ],
      "metadata": {
        "id": "H2WtRT_VTrxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    \n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "3VNrDO6ITxSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,iterator,optimizer,criterion):\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # cleaning the cache of optimizer\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text,text_lengths, labels = batch\n",
        "        \n",
        "        # forward propagation and squeezing\n",
        "        predictions = model(text,text_lengths).squeeze()\n",
        "        \n",
        "        # computing loss / backward propagation\n",
        "        loss = criterion(predictions.double(),labels.double())\n",
        "        loss.backward()\n",
        "        \n",
        "        # accuracy\n",
        "        acc = binary_accuracy(predictions,labels)\n",
        "        \n",
        "        # updating params\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    # It'll return the means of loss and accuracy\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "        "
      ],
      "metadata": {
        "id": "TInRo66fT2FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,iterator,criterion):\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "    \n",
        "    # deactivate the dropouts\n",
        "    model.eval()\n",
        "    \n",
        "    # Sets require_grad flat False\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text,text_lengths, labels = batch\n",
        "            \n",
        "            predictions = model(text,text_lengths).squeeze()\n",
        "              \n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions.double(), labels.double())\n",
        "            acc = binary_accuracy(predictions, labels)\n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "8T-r-NdhT2yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "EPOCH_NUMBER = 15\n",
        "train_loader = DataLoader(train_dataset, \n",
        "                          batch_size=32, \n",
        "                          shuffle=True,\n",
        "                          drop_last=True, \n",
        "                          collate_fn=pad_batched_sequence)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, \n",
        "                          batch_size=32, \n",
        "                          shuffle=True,\n",
        "                          drop_last=True, \n",
        "                          collate_fn=pad_batched_sequence)\n",
        "\n",
        "for epoch in range(1,EPOCH_NUMBER+1):\n",
        "    \n",
        "    train_loss,train_acc = train(model,train_loader,optimizer,criterion)\n",
        "    \n",
        "    valid_loss,valid_acc = evaluate(model,test_loader,criterion)\n",
        "    \n",
        "    # Showing statistics\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "    print()"
      ],
      "metadata": {
        "id": "gYgGYsiFT5S4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d93d7d79-cb8a-4fdb-d7dc-87007154ee35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.692 | Train Acc: 52.11%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 51.88%\n",
            "\n",
            "\tTrain Loss: 0.669 | Train Acc: 58.39%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 53.89%\n",
            "\n",
            "\tTrain Loss: 0.632 | Train Acc: 63.48%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 55.10%\n",
            "\n",
            "\tTrain Loss: 0.589 | Train Acc: 68.44%\n",
            "\t Val. Loss: 0.714 |  Val. Acc: 56.64%\n",
            "\n",
            "\tTrain Loss: 0.542 | Train Acc: 72.23%\n",
            "\t Val. Loss: 0.740 |  Val. Acc: 57.96%\n",
            "\n",
            "\tTrain Loss: 0.497 | Train Acc: 75.29%\n",
            "\t Val. Loss: 0.743 |  Val. Acc: 59.78%\n",
            "\n",
            "\tTrain Loss: 0.457 | Train Acc: 78.12%\n",
            "\t Val. Loss: 0.779 |  Val. Acc: 59.41%\n",
            "\n",
            "\tTrain Loss: 0.414 | Train Acc: 80.82%\n",
            "\t Val. Loss: 0.835 |  Val. Acc: 59.97%\n",
            "\n",
            "\tTrain Loss: 0.380 | Train Acc: 82.61%\n",
            "\t Val. Loss: 0.869 |  Val. Acc: 60.98%\n",
            "\n",
            "\tTrain Loss: 0.344 | Train Acc: 84.58%\n",
            "\t Val. Loss: 0.956 |  Val. Acc: 60.26%\n",
            "\n",
            "\tTrain Loss: 0.310 | Train Acc: 86.54%\n",
            "\t Val. Loss: 0.977 |  Val. Acc: 62.02%\n",
            "\n",
            "\tTrain Loss: 0.278 | Train Acc: 88.12%\n",
            "\t Val. Loss: 1.016 |  Val. Acc: 61.99%\n",
            "\n",
            "\tTrain Loss: 0.249 | Train Acc: 89.44%\n",
            "\t Val. Loss: 1.097 |  Val. Acc: 61.85%\n",
            "\n",
            "\tTrain Loss: 0.221 | Train Acc: 90.92%\n",
            "\t Val. Loss: 1.139 |  Val. Acc: 62.31%\n",
            "\n",
            "\tTrain Loss: 0.197 | Train Acc: 92.14%\n",
            "\t Val. Loss: 1.231 |  Val. Acc: 61.68%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3"
      ],
      "metadata": {
        "id": "LNKEaW3SfcTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = '/content/drive/MyDrive/data'\n",
        "\n",
        "train_data_path = f'{data_path}/train'\n",
        "true_train_path = f'{train_data_path}/true.csv'\n",
        "false_train_path = f'{train_data_path}/false.csv'\n",
        "\n",
        "test_data_path = f'{data_path}/test'\n",
        "true_test_path = f'{test_data_path}/true.csv'\n",
        "false_test_path = f'{test_data_path}/false.csv'"
      ],
      "metadata": {
        "id": "TZ0ZIOuCLJbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc7f9d3-3e18-4f0b-db2c-b6f3ee475b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_dim=768, num_class=1):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\").cuda()\n",
        "        self.fc = nn.Linear(embed_dim, num_class).cuda()\n",
        "        self.sigmoid = nn.Sigmoid().cuda()\n",
        "\n",
        "    def forward(self, input_ids, attention_masks):\n",
        "        inputs = {\n",
        "            \"input_ids\": input_ids.cuda(), \n",
        "            \"attention_mask\" : attention_masks.cuda()\n",
        "        }\n",
        "        outputs = self.bert(**inputs)\n",
        "        output = outputs.last_hidden_state\n",
        "        output = output[:,0,:]\n",
        "        output = self.fc(output)\n",
        "        return self.sigmoid(output)\n"
      ],
      "metadata": {
        "id": "U4XLqdtW8rN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpellCheckingDataset(Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, data_paths, labels, batch_size=32):\n",
        "        self.dataset = []\n",
        "        for i in range(len(data_paths)):\n",
        "          data_path = data_paths[i]\n",
        "          with open(data_path, 'r', encoding='utf-8') as file:\n",
        "              data = csv.reader(file)\n",
        "              for item in data:\n",
        "                self.dataset.append((item[0], labels[i]))\n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if (self.tokenizer == None):\n",
        "          raise Exception('Tokenizer cannot be null')\n",
        "\n",
        "        tweet, label = self.dataset[idx]\n",
        "        tokenized_tweet = self.tokenizer(tweet)\n",
        "        input_ids = tokenized_tweet['input_ids']\n",
        "        attention_mask = tokenized_tweet['attention_mask']\n",
        "\n",
        "        return input_ids, attention_mask, label\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "class LMSpellCheckingDataset(Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, data_paths, labels, batch_size=32):\n",
        "        self.dataset = []\n",
        "        for i in range(len(data_paths)):\n",
        "          data_path = data_paths[i]\n",
        "          with open(data_path, 'r', encoding='utf-8') as file:\n",
        "              data = csv.reader(file)\n",
        "              for item in data:\n",
        "                self.dataset.append((item[0], labels[i]))\n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if (self.tokenizer == None):\n",
        "          raise Exception('Tokenizer cannot be null')\n",
        "\n",
        "        tweet, label = self.dataset[idx]\n",
        "        tokenized_tweet = self.tokenizer(tweet)\n",
        "        input_ids = tokenized_tweet['input_ids']\n",
        "        attention_mask = tokenized_tweet['attention_mask']\n",
        "\n",
        "        return torch.tensor(input_ids)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.dataset)"
      ],
      "metadata": {
        "id": "f0PokHctSoa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def pad_batched_sequence(batch):\n",
        "    \n",
        "    input_ids = [torch.tensor(item[0]) for item in batch]\n",
        "\n",
        "    attention_masks =  [torch.tensor(item[1]) for item in batch]\n",
        "\n",
        "    input_ids = pad_sequence(input_ids, padding_value=0, batch_first=True)\n",
        "\n",
        "    attention_masks = pad_sequence(attention_masks, \n",
        "                                   padding_value=0, \n",
        "                                   batch_first=True)\n",
        "\n",
        "    labels = None\n",
        "    \n",
        "    if batch[0][2] is not None:\n",
        "        labels = torch.tensor([[item[2]] for item in batch]).double().cuda()\n",
        "    \n",
        "    return input_ids.cuda(), attention_masks.cuda(), labels\n",
        "\n",
        "class SpellCheckingTrainer():\n",
        "\n",
        "  def __init__(self,\n",
        "               model,\n",
        "               train_dataset,\n",
        "               save_data_path,\n",
        "               batch_size=32,\n",
        "               epochs=20,\n",
        "               lr=0.001):\n",
        "        \n",
        "    self.model = model\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.train_loader = DataLoader(train_dataset, \n",
        "                                   batch_size=batch_size, \n",
        "                                   shuffle=True, \n",
        "                                   drop_last=True, \n",
        "                                   collate_fn=pad_batched_sequence)\n",
        "    self.save_path = save_data_path\n",
        "    self.loss_function = nn.BCELoss()\n",
        "    self.optimizer = torch.optim.Adam(list(self.model.parameters()), lr=lr)        \n",
        "    self.accuracy = Accuracy(num_classes=1)\n",
        "\n",
        "  def train_one_epoch(self, epoch_index):\n",
        "    running_loss = 0.\n",
        "    running_accuracy = 0.\n",
        "    last_loss = 0.\n",
        "    threshold = torch.tensor([0.5]).cuda()\n",
        "\n",
        "    for i, data in tqdm.tqdm(enumerate(self.train_loader), \n",
        "                             total=len(self.train_loader)):\n",
        "        # Every data instance is an input + label pair\n",
        "        input_ids, attention_masks, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = self.model(input_ids, attention_masks)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = self.loss_function(outputs.double(), labels.double())\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        result = (outputs > threshold).float() * 1\n",
        "        running_accuracy += torch.sum(result == labels) / self.batch_size\n",
        "        \n",
        "        if i % 10 == 9:\n",
        "            last_loss = running_loss / 10 # loss per batch\n",
        "            last_accuracy = running_accuracy / 10 # accuracy per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            print('  batch {} accuracy: {}'.format(i + 1, last_accuracy))\n",
        "            running_loss = 0.\n",
        "            running_accuracy = 0.\n",
        "\n",
        "    return last_loss\n",
        "\n",
        "\n",
        "  def train(self):\n",
        "    epoch_number = 0\n",
        "    for epoch in range(self.epochs):\n",
        "        print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "        # Make sure gradient tracking is on, and do a pass over the data\n",
        "        self.model.train(True)\n",
        "        avg_loss = self.train_one_epoch(epoch_number)\n",
        "\n",
        "        # We don't need gradients on to do reporting\n",
        "        self.model.train(False)\n",
        "\n",
        "        epoch_number += 1\n",
        "    \n",
        "    torch.save(self.model.state_dict(), self.save_path)\n",
        "    \n",
        "          \n",
        "          "
      ],
      "metadata": {
        "id": "jByNbykLSq_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "true_label = 1\n",
        "false_label = 0\n",
        "\n",
        "true_train_dataset = SpellCheckingDataset(tokenizer, [true_train_path], [true_label])\n",
        "false_train_dataset = SpellCheckingDataset(tokenizer, [false_train_path], [false_label])\n",
        "\n",
        "test_dataset = SpellCheckingDataset(tokenizer, \n",
        "                                    [true_test_path, false_test_path],\n",
        "                                    [true_label, false_label])\n",
        "\n",
        "true_saved_model_path = '/content/drive/MyDrive/models/true_bert.berm_lm'\n",
        "false_saved_model_path = '/content/drive/MyDrive/models/false_bert.berm_lm'\n",
        "\n",
        "true_trainer = SpellCheckingTrainer(TextClassificationModel(), \n",
        "                                    true_train_dataset,\n",
        "                                    true_saved_model_path)\n",
        "\n",
        "false_trainer = SpellCheckingTrainer(TextClassificationModel(), \n",
        "                                     false_train_dataset,\n",
        "                                     false_saved_model_path)\n",
        " "
      ],
      "metadata": {
        "id": "hlku2sOhrGsd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321,
          "referenced_widgets": [
            "8fbfce73ee8f49cc9ed7a9c7dd1d7588",
            "ad95ba6f910348bf84b1af4125a8df47",
            "8d2746a2baf742e6a9a326ebd3ed66fa",
            "e936063d4ea846339c457ca839070200",
            "4300d142c542434889a9114de1f1b44e",
            "aa9285437595493c92e769fad231c342",
            "9df9c2f62da34912ad38c174aa5f77c7",
            "efb82247ac1a4ef599a5308c89abc95d",
            "e01e3ed8f5af4214a958fabf38e73fae",
            "1c4ccfa982794d349e636eb63946ef63",
            "535e8eec2e01409bbf4593cc50863f3a",
            "62ad2b1f2af54b64be94601c5fded6d0",
            "7cb69534eeb148639c143413b84d1d4f",
            "3ddcb55071c94797b3d6fcf8dd5587cf",
            "7eba31afbd694c04bd7f9f0f8e66474c",
            "4d97e565daf04104b97a3ca81f6fea31",
            "a28d125471264b9881af34c51581e2f3",
            "be8b5f578dc747a0a64d21bacf81d4d6",
            "e65f44f363e94454a3a335a771af37bf",
            "7d1406202c934cf79e3eaec8a92ad0e8",
            "b698558e164a4a8c8e638aba9be42995",
            "3c107c00272f4f4b9651e179f8fd8a41",
            "f8809da8a44d4b9c89a390822f7a4bea",
            "91162d25c8414b33b83bd38b23c3811a",
            "a5acea2712344fd287a607aed663c141",
            "7d991f2d08514a27b903a0a9e156b150",
            "ca11ccbf11694f158b3b92a0e9ed1bba",
            "2e1ab985b17a489fa405b90a3202e0f2",
            "ef700d3c96704717843167964a7f97bf",
            "b7c4d19b535e4c70992d638ffd3599a9",
            "4e3de5edd0944c9196084d9568ac6765",
            "9ff4e8ff298d425895eb0005671a0d96",
            "96dbd94584d84fd8a10ceffece909a14",
            "0ac43a3e8b984c648ce96840e44e22b2",
            "557554784b2144aab42c06fc38d81a07",
            "19247f58829b4221b1e1d93a00db0043",
            "5484901372bd429f93d9257987efc848",
            "108ac2f75225467f83c03a32cff930e7",
            "aec37c23ae03488fa944df2d81c1f385",
            "c64bbb0e3a674e5e9b8c6d0632574ee6",
            "9b8e83685380434385abdaba9c434a5d",
            "507e6976da4746cbb8f934897b20a0d0",
            "54b5b1c653924c639ccdcc2a1b3eedb8",
            "e067b7c73a7746ecb813745562cfad58"
          ]
        },
        "outputId": "806b42aa-f113-4f2a-c1fd-ea081816768b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fbfce73ee8f49cc9ed7a9c7dd1d7588"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62ad2b1f2af54b64be94601c5fded6d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8809da8a44d4b9c89a390822f7a4bea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ac43a3e8b984c648ce96840e44e22b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_trainer.train()\n",
        "false_trainer.train()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550ae340-aacf-4763-ddd1-f2c9f9bdd7fb",
        "id": "xoXD9h7vfhsS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 10/403 [00:03<02:13,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 10 loss: 0.0809702505817\n",
            "  batch 10 accuracy: 0.90625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 20/403 [00:06<02:03,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 20 loss: 9.74941587150786e-05\n",
            "  batch 20 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 30/403 [00:10<02:06,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 30 loss: 7.665900075088309e-05\n",
            "  batch 30 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 40/403 [00:13<02:01,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 40 loss: 6.321273556593354e-05\n",
            "  batch 40 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 50/403 [00:16<02:01,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 50 loss: 5.304097863122118e-05\n",
            "  batch 50 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 60/403 [00:20<01:56,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 60 loss: 4.5547186205881256e-05\n",
            "  batch 60 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 70/403 [00:23<01:49,  3.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 70 loss: 3.9787640177359925e-05\n",
            "  batch 70 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 80/403 [00:26<01:51,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 80 loss: 3.525267347145879e-05\n",
            "  batch 80 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 90/403 [00:30<01:52,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 90 loss: 3.170458740125791e-05\n",
            "  batch 90 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 100/403 [00:33<01:43,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100 loss: 2.8935122533390755e-05\n",
            "  batch 100 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 110/403 [00:37<01:43,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 110 loss: 2.6636554094839917e-05\n",
            "  batch 110 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 120/403 [00:40<01:41,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 120 loss: 2.491654307511618e-05\n",
            "  batch 120 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 130/403 [00:44<01:36,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 130 loss: 2.305795099310669e-05\n",
            "  batch 130 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 140/403 [00:47<01:31,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 140 loss: 2.1738423486908814e-05\n",
            "  batch 140 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 150/403 [00:51<01:29,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 150 loss: 2.0418897750883825e-05\n",
            "  batch 150 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 160/403 [00:55<01:27,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 160 loss: 1.9377658321589114e-05\n",
            "  batch 160 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 170/403 [00:58<01:20,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 170 loss: 1.8309597432919868e-05\n",
            "  batch 170 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 180/403 [01:02<01:15,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 180 loss: 1.7340259636269857e-05\n",
            "  batch 180 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 190/403 [01:05<01:19,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 190 loss: 1.6409666386565475e-05\n",
            "  batch 190 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 200/403 [01:09<01:14,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200 loss: 1.5627715316709767e-05\n",
            "  batch 200 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 210/403 [01:12<01:08,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 210 loss: 1.4994406221393324e-05\n",
            "  batch 210 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 220/403 [01:16<01:06,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 220 loss: 1.4252690068359558e-05\n",
            "  batch 220 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 230/403 [01:20<01:06,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 230 loss: 1.3673771893515073e-05\n",
            "  batch 230 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 240/403 [01:23<00:57,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 240 loss: 1.3108637743068882e-05\n",
            "  batch 240 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 250/403 [01:27<00:52,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 250 loss: 1.2597148740918153e-05\n",
            "  batch 250 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 260/403 [01:30<00:50,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 260 loss: 1.2024564569842986e-05\n",
            "  batch 260 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 270/403 [01:34<00:49,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 270 loss: 1.1501155152340908e-05\n",
            "  batch 270 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 280/403 [01:38<00:45,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 280 loss: 1.1081682658301286e-05\n",
            "  batch 280 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 290/403 [01:41<00:37,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 290 loss: 1.0680464593949693e-05\n",
            "  batch 290 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 300/403 [01:45<00:34,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 300 loss: 1.025801221713314e-05\n",
            "  batch 300 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 310/403 [01:48<00:32,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 310 loss: 9.864990090937238e-06\n",
            "  batch 310 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 320/403 [01:52<00:28,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 320 loss: 9.444773294338556e-06\n",
            "  batch 320 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 330/403 [01:55<00:24,  3.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 330 loss: 9.10316099819139e-06\n",
            "  batch 330 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 340/403 [01:58<00:21,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 340 loss: 8.711256937489243e-06\n",
            "  batch 340 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 350/403 [02:02<00:18,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 350 loss: 8.334254327664292e-06\n",
            "  batch 350 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 360/403 [02:05<00:14,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 360 loss: 8.08316768123915e-06\n",
            "  batch 360 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 370/403 [02:09<00:11,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 370 loss: 7.80898418846819e-06\n",
            "  batch 370 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 380/403 [02:12<00:07,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 380 loss: 7.509841063534641e-06\n",
            "  batch 380 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 390/403 [02:16<00:04,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 390 loss: 7.2412456212096496e-06\n",
            "  batch 390 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 400/403 [02:19<00:01,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 400 loss: 7.040451081027228e-06\n",
            "  batch 400 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 403/403 [02:21<00:00,  2.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 10/403 [00:03<02:24,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 10 loss: 6.685428441123563e-06\n",
            "  batch 10 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 20/403 [00:07<02:22,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 20 loss: 6.439557668171569e-06\n",
            "  batch 20 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 30/403 [00:10<02:15,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 30 loss: 6.238018198450572e-06\n",
            "  batch 30 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 40/403 [00:14<02:10,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 40 loss: 5.998108032219447e-06\n",
            "  batch 40 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 50/403 [00:18<02:12,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 50 loss: 5.739943863123175e-06\n",
            "  batch 50 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 60/403 [00:21<02:01,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 60 loss: 5.600244717112281e-06\n",
            "  batch 60 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 70/403 [00:25<01:55,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 70 loss: 5.362197343447454e-06\n",
            "  batch 70 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 80/403 [00:28<01:50,  2.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 80 loss: 5.183754988794325e-06\n",
            "  batch 80 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 90/403 [00:32<01:51,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 90 loss: 5.026174404764259e-06\n",
            "  batch 90 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 100/403 [00:36<01:58,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100 loss: 4.839163919218084e-06\n",
            "  batch 100 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 110/403 [00:39<01:49,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 110 loss: 4.668172264800533e-06\n",
            "  batch 110 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 120/403 [00:43<01:39,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 120 loss: 4.541884359620236e-06\n",
            "  batch 120 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 130/403 [00:47<01:36,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 130 loss: 4.364187216549926e-06\n",
            "  batch 130 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 140/403 [00:50<01:28,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 140 loss: 4.177176813471847e-06\n",
            "  batch 140 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 150/403 [00:53<01:24,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 150 loss: 4.037105333499139e-06\n",
            "  batch 150 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 160/403 [00:57<01:24,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 160 loss: 3.976382892578533e-06\n",
            "  batch 160 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 170/403 [01:00<01:18,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 170 loss: 3.7826670046668317e-06\n",
            "  batch 170 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 180/403 [01:04<01:15,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 180 loss: 3.6500461870483907e-06\n",
            "  batch 180 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 190/403 [01:07<01:17,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 190 loss: 3.541639860797967e-06\n",
            "  batch 190 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 200/403 [01:11<01:14,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200 loss: 3.449624872567994e-06\n",
            "  batch 200 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 210/403 [01:14<01:06,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 210 loss: 3.3333954101563583e-06\n",
            "  batch 210 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 220/403 [01:18<01:03,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 220 loss: 3.255909160827826e-06\n",
            "  batch 220 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 230/403 [01:22<01:02,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 230 loss: 3.1128575082579684e-06\n",
            "  batch 230 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 240/403 [01:25<00:59,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 240 loss: 2.9970006208619344e-06\n",
            "  batch 240 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 250/403 [01:29<00:53,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 250 loss: 2.916906645520316e-06\n",
            "  batch 250 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 260/403 [01:32<00:51,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 260 loss: 2.8304796507141796e-06\n",
            "  batch 260 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 270/403 [01:36<00:47,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 270 loss: 2.750758234844919e-06\n",
            "  batch 270 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 280/403 [01:39<00:44,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 280 loss: 2.6337837761023924e-06\n",
            "  batch 280 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 290/403 [01:43<00:38,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 290 loss: 2.544749108396631e-06\n",
            "  batch 290 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 300/403 [01:46<00:35,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 300 loss: 2.508613733681888e-06\n",
            "  batch 300 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 310/403 [01:50<00:32,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 310 loss: 2.430009903503232e-06\n",
            "  batch 310 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 320/403 [01:53<00:29,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 320 loss: 2.33464223600622e-06\n",
            "  batch 320 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 330/403 [01:57<00:24,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 330 loss: 2.280252878898963e-06\n",
            "  batch 330 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 340/403 [02:00<00:22,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 340 loss: 2.186747873759711e-06\n",
            "  batch 340 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 350/403 [02:04<00:18,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 350 loss: 2.133476103586534e-06\n",
            "  batch 350 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 360/403 [02:07<00:14,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 360 loss: 2.1223002476571e-06\n",
            "  batch 360 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 370/403 [02:11<00:11,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 370 loss: 2.050774511878096e-06\n",
            "  batch 370 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 380/403 [02:14<00:07,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 380 loss: 1.9945225057357903e-06\n",
            "  batch 380 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 390/403 [02:18<00:04,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 390 loss: 1.9021351151087097e-06\n",
            "  batch 390 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 400/403 [02:21<00:01,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 400 loss: 1.8477457748325016e-06\n",
            "  batch 400 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 403/403 [02:22<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 10/403 [00:03<02:17,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 10 loss: 1.772494771270465e-06\n",
            "  batch 10 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 20/403 [00:07<02:20,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 20 loss: 1.7270461465843808e-06\n",
            "  batch 20 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 30/403 [00:10<02:16,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 30 loss: 1.655892973963622e-06\n",
            "  batch 30 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 40/403 [00:14<02:02,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 40 loss: 1.6205026672117424e-06\n",
            "  batch 40 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 50/403 [00:17<02:04,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 50 loss: 1.5687210426455897e-06\n",
            "  batch 50 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 60/403 [00:21<01:56,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 60 loss: 1.5676034761840793e-06\n",
            "  batch 60 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 70/403 [00:24<02:01,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 70 loss: 1.4569621573880241e-06\n",
            "  batch 70 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 80/403 [00:28<01:56,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 80 loss: 1.4565896335318352e-06\n",
            "  batch 80 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 90/403 [00:31<01:48,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 90 loss: 1.400337669889054e-06\n",
            "  batch 90 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 100/403 [00:35<01:45,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100 loss: 1.3396153419896554e-06\n",
            "  batch 100 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 110/403 [00:38<01:50,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 110 loss: 1.3165185098094439e-06\n",
            "  batch 110 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 120/403 [00:42<01:41,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 120 loss: 1.2647369074922433e-06\n",
            "  batch 120 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 130/403 [00:45<01:37,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 130 loss: 1.2692072694839648e-06\n",
            "  batch 130 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 140/403 [00:49<01:37,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 140 loss: 1.2487181557671881e-06\n",
            "  batch 140 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 150/403 [00:53<01:29,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 150 loss: 1.1812903030213163e-06\n",
            "  batch 150 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 160/403 [00:56<01:27,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 160 loss: 1.1790551351039134e-06\n",
            "  batch 160 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 170/403 [01:00<01:20,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 170 loss: 1.1559583146476969e-06\n",
            "  batch 170 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 180/403 [01:03<01:16,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 180 loss: 1.1239207708741612e-06\n",
            "  batch 180 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 190/403 [01:07<01:15,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 190 loss: 1.0736292957341923e-06\n",
            "  batch 190 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 200/403 [01:10<01:17,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200 loss: 1.0378664679682866e-06\n",
            "  batch 200 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 210/403 [01:14<01:07,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 210 loss: 1.0337686611855444e-06\n",
            "  batch 210 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 220/403 [01:17<01:05,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 220 loss: 1.0289257843082594e-06\n",
            "  batch 220 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 230/403 [01:21<01:05,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 230 loss: 1.0117894247324221e-06\n",
            "  batch 230 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 240/403 [01:25<00:56,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 240 loss: 9.682034777252073e-07\n",
            "  batch 240 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 250/403 [01:28<00:53,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 250 loss: 9.268527051191038e-07\n",
            "  batch 250 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 260/403 [01:32<00:51,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 260 loss: 8.840118256751149e-07\n",
            "  batch 260 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 270/403 [01:35<00:49,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 270 loss: 8.527193459564894e-07\n",
            "  batch 270 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 280/403 [01:39<00:45,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 280 loss: 8.702282411124897e-07\n",
            "  batch 280 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 290/403 [01:43<00:41,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 290 loss: 8.735810212771479e-07\n",
            "  batch 290 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 300/403 [01:46<00:34,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 300 loss: 8.501116736340544e-07\n",
            "  batch 300 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 310/403 [01:50<00:35,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 310 loss: 7.998201982276162e-07\n",
            "  batch 310 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 320/403 [01:53<00:29,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 320 loss: 8.210543866574756e-07\n",
            "  batch 320 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 330/403 [01:56<00:24,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 330 loss: 7.834289118105511e-07\n",
            "  batch 330 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 340/403 [02:00<00:22,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 340 loss: 7.480386129634634e-07\n",
            "  batch 340 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 350/403 [02:04<00:18,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 350 loss: 7.025900263359417e-07\n",
            "  batch 350 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 360/403 [02:07<00:15,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 360 loss: 7.167461566039926e-07\n",
            "  batch 360 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 370/403 [02:11<00:10,  3.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 370 loss: 7.182362761428684e-07\n",
            "  batch 370 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 380/403 [02:14<00:08,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 380 loss: 6.888064554957071e-07\n",
            "  batch 380 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 390/403 [02:18<00:04,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 390 loss: 6.776305777613422e-07\n",
            "  batch 390 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 400/403 [02:21<00:01,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 400 loss: 6.51926060291254e-07\n",
            "  batch 400 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 403/403 [02:22<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 4:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 10/403 [00:03<02:27,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 10 loss: 6.482007689713859e-07\n",
            "  batch 10 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 20/403 [00:07<02:19,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 20 loss: 6.098302482772481e-07\n",
            "  batch 20 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 30/403 [00:10<02:14,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 30 loss: 6.042423091658148e-07\n",
            "  batch 30 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 40/403 [00:14<02:05,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 40 loss: 6.049873679360492e-07\n",
            "  batch 40 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 50/403 [00:18<02:08,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 50 loss: 6.161632537084413e-07\n",
            "  batch 50 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 60/403 [00:21<02:01,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 60 loss: 5.997719632057497e-07\n",
            "  batch 60 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 70/403 [00:25<01:54,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 70 loss: 5.640091397031116e-07\n",
            "  batch 70 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 80/403 [00:28<01:56,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 80 loss: 5.360694434354087e-07\n",
            "  batch 80 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 90/403 [00:32<01:55,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 90 loss: 5.669893927697029e-07\n",
            "  batch 90 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 100/403 [00:35<01:45,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100 loss: 5.193056360043187e-07\n",
            "  batch 100 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 110/403 [00:39<01:44,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 110 loss: 5.573036450547344e-07\n",
            "  batch 110 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 120/403 [00:42<01:38,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 120 loss: 5.16697931796189e-07\n",
            "  batch 120 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 130/403 [00:46<01:39,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 130 loss: 4.865230673890375e-07\n",
            "  batch 130 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 140/403 [00:49<01:30,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 140 loss: 5.01424241683529e-07\n",
            "  batch 140 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 150/403 [00:53<01:32,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 150 loss: 4.85405481254291e-07\n",
            "  batch 150 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 160/403 [00:57<01:27,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 160 loss: 4.783274279774701e-07\n",
            "  batch 160 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 170/403 [01:00<01:23,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 170 loss: 4.83542839635576e-07\n",
            "  batch 170 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 180/403 [01:04<01:19,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 180 loss: 4.541130256053582e-07\n",
            "  batch 180 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 190/403 [01:07<01:17,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 190 loss: 4.4256461317899814e-07\n",
            "  batch 190 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 200/403 [01:11<01:12,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200 loss: 4.2691838042513215e-07\n",
            "  batch 200 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 210/403 [01:14<01:08,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 210 loss: 4.287810296377856e-07\n",
            "  batch 210 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 220/403 [01:18<01:05,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 220 loss: 4.3846679631539114e-07\n",
            "  batch 220 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 230/403 [01:22<01:02,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 230 loss: 4.0791939082134485e-07\n",
            "  batch 230 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 240/403 [01:25<00:56,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 240 loss: 4.217029836440376e-07\n",
            "  batch 240 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 250/403 [01:29<00:53,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 250 loss: 3.9562593205926813e-07\n",
            "  batch 250 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 260/403 [01:32<00:49,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 260 loss: 3.915281158617959e-07\n",
            "  batch 260 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 270/403 [01:35<00:47,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 270 loss: 4.094095245266853e-07\n",
            "  batch 270 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 280/403 [01:39<00:45,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 280 loss: 3.5613783997416593e-07\n",
            "  batch 280 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 290/403 [01:43<00:40,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 290 loss: 3.4719714059332174e-07\n",
            "  batch 290 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 300/403 [01:46<00:34,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 300 loss: 3.408641454206032e-07\n",
            "  batch 300 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 310/403 [01:50<00:31,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 310 loss: 3.390015039795263e-07\n",
            "  batch 310 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 320/403 [01:53<00:28,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 320 loss: 3.360212736059334e-07\n",
            "  batch 320 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 330/403 [01:57<00:24,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 330 loss: 3.192574493438331e-07\n",
            "  batch 330 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 340/403 [02:00<00:22,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 340 loss: 3.144145742873074e-07\n",
            "  batch 340 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 350/403 [02:04<00:19,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 350 loss: 3.054738676677978e-07\n",
            "  batch 350 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 360/403 [02:07<00:14,  2.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 360 loss: 2.9988592797904877e-07\n",
            "  batch 360 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 370/403 [02:11<00:11,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 370 loss: 3.1515963208054543e-07\n",
            "  batch 370 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 380/403 [02:14<00:08,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 380 loss: 3.0659145602299094e-07\n",
            "  batch 380 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 390/403 [02:18<00:04,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 390 loss: 2.928078780773126e-07\n",
            "  batch 390 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 400/403 [02:21<00:01,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 400 loss: 2.913177591601613e-07\n",
            "  batch 400 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 403/403 [02:22<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 10/403 [00:03<02:23,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 10 loss: 2.946705243145616e-07\n",
            "  batch 10 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 20/403 [00:07<02:22,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 20 loss: 3.296882739479023e-07\n",
            "  batch 20 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 30/403 [00:10<02:19,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 30 loss: 3.0510134452214245e-07\n",
            "  batch 30 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 40/403 [00:14<02:20,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 40 loss: 3.088266356643724e-07\n",
            "  batch 40 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 50/403 [00:17<01:59,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 50 loss: 2.9802328418429226e-07\n",
            "  batch 50 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 60/403 [00:21<02:04,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 60 loss: 3.024936461760061e-07\n",
            "  batch 60 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 70/403 [00:25<01:59,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 70 loss: 2.8312211783900716e-07\n",
            "  batch 70 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 80/403 [00:28<01:50,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 80 loss: 2.8423971014660046e-07\n",
            "  batch 80 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 90/403 [00:32<01:56,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 90 loss: 2.7976935810250133e-07\n",
            "  batch 90 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 100/403 [00:35<01:54,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100 loss: 2.592802518464224e-07\n",
            "  batch 100 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 110/403 [00:39<01:46,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 110 loss: 2.633780776362341e-07\n",
            "  batch 110 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 120/403 [00:42<01:39,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 120 loss: 2.522022118922933e-07\n",
            "  batch 120 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 130/403 [00:46<01:31,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 130 loss: 2.458692110796317e-07\n",
            "  batch 130 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 140/403 [00:49<01:34,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 140 loss: 2.2388998839330525e-07\n",
            "  batch 140 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 150/403 [00:53<01:26,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 150 loss: 2.156943492481927e-07\n",
            "  batch 150 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 160/403 [00:56<01:22,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 160 loss: 2.160668771011998e-07\n",
            "  batch 160 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 170/403 [01:00<01:23,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 170 loss: 2.0451847413395578e-07\n",
            "  batch 170 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 180/403 [01:04<01:20,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 180 loss: 1.9967559485857515e-07\n",
            "  batch 180 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 190/403 [01:07<01:14,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 190 loss: 1.8775466243960054e-07\n",
            "  batch 190 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 200/403 [01:11<01:10,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200 loss: 2.1085147472456994e-07\n",
            "  batch 200 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 210/403 [01:14<01:07,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 210 loss: 1.7844143200830067e-07\n",
            "  batch 210 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 220/403 [01:18<01:05,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 220 loss: 1.8291178320862792e-07\n",
            "  batch 220 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 230/403 [01:22<01:01,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 230 loss: 1.8589201944420422e-07\n",
            "  batch 230 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 240/403 [01:25<00:58,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 240 loss: 2.0228330284146145e-07\n",
            "  batch 240 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 250/403 [01:29<00:52,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 250 loss: 1.9036236913462658e-07\n",
            "  batch 250 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 260/403 [01:32<00:50,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 260 loss: 1.6652049950050734e-07\n",
            "  batch 260 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 270/403 [01:36<00:47,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 270 loss: 1.739710847603713e-07\n",
            "  batch 270 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 280/403 [01:39<00:42,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 280 loss: 1.8142167330649972e-07\n",
            "  batch 280 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 290/403 [01:43<00:40,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 290 loss: 1.881271928239192e-07\n",
            "  batch 290 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 300/403 [01:46<00:35,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 300 loss: 1.6912820490767376e-07\n",
            "  batch 300 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 310/403 [01:50<00:34,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 310 loss: 1.6763809074228432e-07\n",
            "  batch 310 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 320/403 [01:53<00:28,  2.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 320 loss: 1.6428532758628856e-07\n",
            "  batch 320 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 330/403 [01:57<00:24,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 330 loss: 1.4826657066536097e-07\n",
            "  batch 330 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 340/403 [02:00<00:22,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 340 loss: 1.6056003497856136e-07\n",
            "  batch 340 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 350/403 [02:04<00:18,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 350 loss: 1.6205014985449346e-07\n",
            "  batch 350 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 360/403 [02:07<00:15,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 360 loss: 1.5720727328806068e-07\n",
            "  batch 360 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 370/403 [02:11<00:11,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 370 loss: 1.739710860038223e-07\n",
            "  batch 370 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 380/403 [02:14<00:07,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 380 loss: 1.6428532891855942e-07\n",
            "  batch 380 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 390/403 [02:18<00:04,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 390 loss: 1.631677377211889e-07\n",
            "  batch 390 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 400/403 [02:21<00:01,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 400 loss: 1.6503038529070841e-07\n",
            "  batch 400 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 403/403 [02:22<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 6:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 10/403 [00:03<02:17,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 10 loss: 1.6912820699489545e-07\n",
            "  batch 10 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 20/403 [00:06<02:08,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 20 loss: 1.6428532754187936e-07\n",
            "  batch 20 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 30/403 [00:10<02:06,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 30 loss: 1.7434361461178357e-07\n",
            "  batch 30 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 40/403 [00:13<02:05,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 40 loss: 1.7248096624290227e-07\n",
            "  batch 40 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 50/403 [00:17<02:03,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 50 loss: 1.6056003302456612e-07\n",
            "  batch 50 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 60/403 [00:20<01:56,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 60 loss: 1.6912820774984882e-07\n",
            "  batch 60 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 70/403 [00:24<02:03,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 70 loss: 1.5459956881348257e-07\n",
            "  batch 70 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 80/403 [00:28<01:51,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 80 loss: 1.6056003524501452e-07\n",
            "  batch 80 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 90/403 [00:31<01:47,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 90 loss: 1.609325630092047e-07\n",
            "  batch 90 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 100/403 [00:35<01:48,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100 loss: 1.6652050123245785e-07\n",
            "  batch 100 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 110/403 [00:38<01:46,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 110 loss: 1.4714898266543875e-07\n",
            "  batch 110 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 120/403 [00:42<01:38,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 120 loss: 1.6093256545169844e-07\n",
            "  batch 120 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 130/403 [00:45<01:40,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 130 loss: 1.5087427727157007e-07\n",
            "  batch 130 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 140/403 [00:49<01:34,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 140 loss: 1.5832485737999335e-07\n",
            "  batch 140 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 150/403 [00:53<01:35,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 150 loss: 1.437962197314877e-07\n",
            "  batch 150 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 160/403 [00:56<01:22,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 160 loss: 1.6316773714387293e-07\n",
            "  batch 160 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 170/403 [01:00<01:21,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 170 loss: 1.4677645387984223e-07\n",
            "  batch 170 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 180/403 [01:03<01:21,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 180 loss: 1.6093256443029256e-07\n",
            "  batch 180 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 190/403 [01:07<01:16,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 190 loss: 1.6018750481628608e-07\n",
            "  batch 190 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 200/403 [01:11<01:17,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200 loss: 1.5534462425304533e-07\n",
            "  batch 200 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 210/403 [01:14<01:09,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 210 loss: 1.6130509303825356e-07\n",
            "  batch 210 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 220/403 [01:18<01:05,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 220 loss: 1.5795232832794295e-07\n",
            "  batch 220 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 230/403 [01:21<00:59,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 230 loss: 1.5459956517194693e-07\n",
            "  batch 230 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 240/403 [01:25<00:55,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 240 loss: 1.5124680401435494e-07\n",
            "  batch 240 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 250/403 [01:28<00:53,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 250 loss: 1.5087427491789484e-07\n",
            "  batch 250 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 260/403 [01:32<00:51,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 260 loss: 1.4081598567195124e-07\n",
            "  batch 260 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 270/403 [01:36<00:48,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 270 loss: 1.5869738629881732e-07\n",
            "  batch 270 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 280/403 [01:39<00:43,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 280 loss: 1.545995661933532e-07\n",
            "  batch 280 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 290/403 [01:43<00:38,  2.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 290 loss: 1.5012921739110976e-07\n",
            "  batch 290 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 300/403 [01:46<00:37,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 300 loss: 1.4528633847100088e-07\n",
            "  batch 300 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 310/403 [01:50<00:33,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 310 loss: 1.3597310888347206e-07\n",
            "  batch 310 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▊  | 317/403 [01:52<00:30,  2.85it/s]"
          ]
        }
      ]
    }
  ]
}